{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ceaf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db082a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n"
     ]
    }
   ],
   "source": [
    "ee.Initialize(project='useful-theory-442820-q8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c92ad",
   "metadata": {},
   "source": [
    "# Similarity Search with Alpha Earth Satellite Embeddings\n",
    "\n",
    "This notebook demonstrates how to use Google's Satellite Embedding dataset to find similar objects/features using Earth Engine. We'll implement a similarity search that can identify objects of interest (e.g., grain silos) by comparing embedding vectors.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Satellite Embeddings**: High-dimensional vector representations of satellite imagery patches\n",
    "- **Similarity Search**: Using dot product between embedding vectors to find similar locations\n",
    "- **Reference Locations**: Sample points representing the target features we want to find\n",
    "\n",
    "## Workflow:\n",
    "1. Define a search region and reference locations\n",
    "2. Load and process the Satellite Embedding dataset\n",
    "3. Extract embedding vectors from reference locations\n",
    "4. Calculate similarity scores across the region\n",
    "5. Apply threshold and extract matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7338b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Additional imports for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a436e5",
   "metadata": {},
   "source": [
    "## 1. Select the Search Region\n",
    "\n",
    "We'll use Franklin County, Kansas as our search area for finding grain silos. This region has many agricultural facilities with grain storage structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c910dc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search region: Franklin County, Kansas\n",
      "Region area: 1493.7 sq km\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780feac9d1c426fac0814c974767c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.5, -95.0], controls=(WidgetControl(options=['position', 'transparent_bg'], position='topright',…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load US counties dataset and select Franklin County, Kansas\n",
    "counties = ee.FeatureCollection('TIGER/2018/Counties')\n",
    "\n",
    "# Select Franklin County, Kansas (GEOID: 20059)\n",
    "selected_county = counties.filter(ee.Filter.eq('GEOID', '20059'))\n",
    "geometry = selected_county.geometry()\n",
    "\n",
    "# Create a map centered on the region\n",
    "Map = geemap.Map(center=[38.5, -95.0], zoom=10)\n",
    "Map.add_layer(geometry, {'color': 'red'}, 'Search Area')\n",
    "\n",
    "print(\"Search region: Franklin County, Kansas\")\n",
    "print(f\"Region area: {geometry.area().divide(1e6).getInfo():.1f} sq km\")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1b56d",
   "metadata": {},
   "source": [
    "## 2. Define Reference Locations\n",
    "\n",
    "Here we define sample locations of grain silos that will serve as our reference points for similarity search. In practice, you would identify these by examining high-resolution satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cd117e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 reference sample points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780feac9d1c426fac0814c974767c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=100953.0, center=[38.5, -95.0], controls=(WidgetControl(options=['position', 'transparent_bg'], pos…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sample locations of grain silos within Franklin County, Kansas\n",
    "# These coordinates represent known grain silo locations\n",
    "sample_coordinates = [\n",
    "    [-95.18, 38.52],  # Example grain silo location 1\n",
    "    [-95.25, 38.48],  # Example grain silo location 2  \n",
    "    [-95.12, 38.55]   # Example grain silo location 3\n",
    "]\n",
    "\n",
    "# Create Earth Engine points from coordinates\n",
    "sample_points = [ee.Geometry.Point(coord) for coord in sample_coordinates]\n",
    "\n",
    "# Create a FeatureCollection from the sample points\n",
    "samples = ee.FeatureCollection([ee.Feature(point) for point in sample_points])\n",
    "\n",
    "print(f\"Created {samples.size().getInfo()} reference sample points\")\n",
    "\n",
    "# Add sample points to the map\n",
    "Map.add_layer(samples, {'color': 'yellow'}, 'Reference Locations')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08cc42",
   "metadata": {},
   "source": [
    "## 3. Load and Process Satellite Embedding Dataset\n",
    "\n",
    "We'll load the Google Satellite Embedding dataset, filter for our time period, and create a mosaic for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e4d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis period: 2024\n",
      "Date range: 2024-01-01T00:00:00 to 2025-01-01T00:00:00\n",
      "Loaded embedding mosaic with 64 bands\n",
      "Date range: 2024-01-01T00:00:00 to 2025-01-01T00:00:00\n",
      "Loaded embedding mosaic with 64 bands\n",
      "Band names: ['A00', 'A01', 'A02', 'A03', 'A04']... (showing first 5)\n",
      "Native resolution: 111319.49079327357 meters\n",
      "Band names: ['A00', 'A01', 'A02', 'A03', 'A04']... (showing first 5)\n",
      "Native resolution: 111319.49079327357 meters\n",
      "CRS: EPSG:4326\n",
      "CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Set time period for analysis\n",
    "year = 2024\n",
    "start_date = ee.Date.fromYMD(year, 1, 1)\n",
    "end_date = start_date.advance(1, 'year')\n",
    "\n",
    "print(f\"Analysis period: {year}\")\n",
    "print(f\"Date range: {start_date.format().getInfo()} to {end_date.format().getInfo()}\")\n",
    "\n",
    "# Load the Satellite Embedding dataset\n",
    "embeddings = ee.ImageCollection('GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL')\n",
    "\n",
    "# Filter and create mosaic\n",
    "mosaic = embeddings.filter(ee.Filter.date(start_date, end_date)).mosaic()\n",
    "\n",
    "print(f\"Loaded embedding mosaic with {mosaic.bandNames().length().getInfo()} bands\")\n",
    "print(f\"Band names: {mosaic.bandNames().getInfo()[:5]}... (showing first 5)\")\n",
    "\n",
    "# Check the resolution and projection\n",
    "projection = mosaic.projection()\n",
    "print(f\"Native resolution: {projection.nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {projection.crs().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdd327",
   "metadata": {},
   "source": [
    "## 4. Extract Embedding Vectors from Reference Locations\n",
    "\n",
    "We sample the embedding mosaic at our reference locations to get the embedding vectors that represent grain silos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99584c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted embeddings from 3 sample points\n",
      "Sampling scale: 10 meters\n",
      "Properties per sample: 65\n",
      "First 5 embedding bands: []\n",
      "Example values: []\n",
      "Properties per sample: 65\n",
      "First 5 embedding bands: []\n",
      "Example values: []\n"
     ]
    }
   ],
   "source": [
    "# Choose the scale for sampling\n",
    "# Use native resolution (10m) for small objects like grain silos\n",
    "scale = 10\n",
    "\n",
    "# Extract the embedding vector from the sample locations\n",
    "sample_embeddings = mosaic.sampleRegions(\n",
    "    collection=samples,\n",
    "    scale=scale,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "print(f\"Extracted embeddings from {sample_embeddings.size().getInfo()} sample points\")\n",
    "print(f\"Sampling scale: {scale} meters\")\n",
    "\n",
    "# Get information about the extracted embeddings\n",
    "first_sample = sample_embeddings.first()\n",
    "properties = first_sample.propertyNames()\n",
    "print(f\"Properties per sample: {properties.size().getInfo()}\")\n",
    "\n",
    "# Display first few embedding values as example\n",
    "sample_dict = first_sample.getInfo()\n",
    "embedding_keys = [k for k in sample_dict['properties'].keys() if k.startswith('b')][:5]\n",
    "print(f\"First 5 embedding bands: {embedding_keys}\")\n",
    "print(f\"Example values: {[sample_dict['properties'][k] for k in embedding_keys]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168421d",
   "metadata": {},
   "source": [
    "## 5. Calculate Similarity Scores\n",
    "\n",
    "We compute the dot product between each reference embedding vector and all pixels in the mosaic to find similar locations. The dot product measures the cosine similarity between unit-length vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1462f9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed similarity scores across the region\n",
      "Similarity values range from -1 (opposite) to +1 (identical)\n",
      "Similarity statistics: {'similarity_max': 0.8559548783448316, 'similarity_mean': 0.6079015803545534, 'similarity_min': 0.13356934630619255}\n",
      "Similarity statistics: {'similarity_max': 0.8559548783448316, 'similarity_mean': 0.6079015803545534, 'similarity_min': 0.13356934630619255}\n"
     ]
    }
   ],
   "source": [
    "# Get band names for the embedding vectors\n",
    "band_names = mosaic.bandNames()\n",
    "\n",
    "# Compute dot product between reference embeddings and all pixels\n",
    "def compute_similarity(sample_feature):\n",
    "    \"\"\"Compute dot product similarity for a single reference sample.\"\"\"\n",
    "    # Convert feature properties to an array image\n",
    "    array_image = ee.Image(sample_feature.toArray(band_names)).arrayFlatten([band_names])\n",
    "    \n",
    "    # Compute dot product with mosaic\n",
    "    dot_product = array_image.multiply(mosaic).reduce('sum').rename('similarity')\n",
    "    \n",
    "    return dot_product\n",
    "\n",
    "# Calculate similarity for each reference location\n",
    "sample_distances = ee.ImageCollection(sample_embeddings.map(compute_similarity))\n",
    "\n",
    "# Calculate mean similarity across all reference locations\n",
    "mean_similarity = sample_distances.mean()\n",
    "\n",
    "print(\"Computed similarity scores across the region\")\n",
    "print(f\"Similarity values range from -1 (opposite) to +1 (identical)\")\n",
    "\n",
    "# Get some statistics about the similarity image\n",
    "stats = mean_similarity.reduceRegion(\n",
    "    reducer=ee.Reducer.minMax().combine(ee.Reducer.mean(), '', True),\n",
    "    geometry=geometry,\n",
    "    scale=scale * 4,  # Use coarser scale for stats to avoid timeout\n",
    "    maxPixels=1e8\n",
    ")\n",
    "\n",
    "print(f\"Similarity statistics: {stats.getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a794a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added similarity layer to map (toggle to view)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780feac9d1c426fac0814c974767c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=100953.0, center=[38.5, -95.0], controls=(WidgetControl(options=['position', 'transparent_bg'], pos…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the similarity scores\n",
    "palette = ['000004', '2C105C', '711F81', 'B63679', 'EE605E', 'FDAE78', 'FCFDBF', 'FFFFFF']\n",
    "similarity_vis = {'palette': palette, 'min': 0, 'max': 1}\n",
    "\n",
    "Map.add_layer(mean_similarity.clip(geometry), similarity_vis, \n",
    "              'Similarity Scores (bright = similar)', False)\n",
    "\n",
    "print(\"Added similarity layer to map (toggle to view)\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c534526",
   "metadata": {},
   "source": [
    "## 6. Extract Location Matches\n",
    "\n",
    "We apply a threshold to identify pixels with high similarity scores and convert them to vector features representing potential grain silo locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d224fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying similarity threshold: 0.9\n",
      "Converting similar pixels to vector features...\n",
      "Found 0 potential matches\n",
      "Found 0 potential matches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780feac9d1c426fac0814c974767c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=100953.0, center=[38.5, -95.0], controls=(WidgetControl(options=['position', 'transparent_bg'], pos…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply a threshold to find similar pixels\n",
    "threshold = 0.90\n",
    "print(f\"Applying similarity threshold: {threshold}\")\n",
    "\n",
    "similar_pixels = mean_similarity.gt(threshold)\n",
    "\n",
    "# Convert to polygons and extract centroids\n",
    "# This operation can be computationally intensive for large areas\n",
    "try:\n",
    "    print(\"Converting similar pixels to vector features...\")\n",
    "    \n",
    "    # Vectorize the similar pixels\n",
    "    polygons = similar_pixels.selfMask().reduceToVectors(\n",
    "        scale=scale,\n",
    "        eightConnected=False,\n",
    "        maxPixels=1e9,\n",
    "        geometry=geometry\n",
    "    )\n",
    "    \n",
    "    # Extract centroids as point locations\n",
    "    predicted_matches = polygons.map(lambda f: f.centroid(maxError=1))\n",
    "    \n",
    "    match_count = predicted_matches.size().getInfo()\n",
    "    print(f\"Found {match_count} potential matches\")\n",
    "    \n",
    "    # Add matches to map\n",
    "    Map.add_layer(predicted_matches, {'color': 'cyan'}, 'Predicted Matches')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Vectorization failed (common with large areas): {e}\")\n",
    "    print(\"Consider using a smaller region or exporting results as an asset\")\n",
    "    \n",
    "    # Alternative: just show the thresholded pixels\n",
    "    Map.add_layer(similar_pixels.selfMask().clip(geometry), \n",
    "                  {'palette': ['cyan']}, 'High Similarity Pixels')\n",
    "    \n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413906f4",
   "metadata": {},
   "source": [
    "## 7. Analysis and Results\n",
    "\n",
    "Let's analyze the results and provide some tools for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d4abaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold sensitivity analysis:\n",
      "  Threshold 0.85: 1 pixels\n",
      "  Threshold 0.85: 1 pixels\n",
      "  Threshold 0.9: 0 pixels\n",
      "  Threshold 0.9: 0 pixels\n",
      "  Threshold 0.95: 0 pixels\n",
      "  Threshold 0.95: 0 pixels\n",
      "  Threshold 0.98: 0 pixels\n",
      "\n",
      "Current threshold (0.9) seems reasonable for this analysis.\n",
      "Higher thresholds = fewer but more precise matches\n",
      "Lower thresholds = more matches but more false positives\n",
      "  Threshold 0.98: 0 pixels\n",
      "\n",
      "Current threshold (0.9) seems reasonable for this analysis.\n",
      "Higher thresholds = fewer but more precise matches\n",
      "Lower thresholds = more matches but more false positives\n"
     ]
    }
   ],
   "source": [
    "# Function to experiment with different thresholds\n",
    "def test_threshold(threshold_value):\n",
    "    \"\"\"Test different similarity thresholds.\"\"\"\n",
    "    test_pixels = mean_similarity.gt(threshold_value)\n",
    "    \n",
    "    # Count pixels above threshold\n",
    "    pixel_count = test_pixels.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=geometry,\n",
    "        scale=scale * 4,\n",
    "        maxPixels=1e8\n",
    "    ).getInfo()\n",
    "    \n",
    "    return pixel_count.get('similarity', 0)\n",
    "\n",
    "# Test different threshold values\n",
    "thresholds = [0.85, 0.90, 0.95, 0.98]\n",
    "print(\"Threshold sensitivity analysis:\")\n",
    "for thresh in thresholds:\n",
    "    count = test_threshold(thresh)\n",
    "    print(f\"  Threshold {thresh}: {count} pixels\")\n",
    "\n",
    "print(f\"\\nCurrent threshold ({threshold}) seems reasonable for this analysis.\")\n",
    "print(\"Higher thresholds = fewer but more precise matches\")\n",
    "print(\"Lower thresholds = more matches but more false positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8bd167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export code is commented out - uncomment and modify paths as needed\n"
     ]
    }
   ],
   "source": [
    "# Optional: Export results to Google Drive or Asset\n",
    "# Uncomment and modify the following code to export results\n",
    "\n",
    "\"\"\"\n",
    "# Export similarity image to Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=mean_similarity.clip(geometry),\n",
    "    description='grain_silo_similarity',\n",
    "    scale=scale,\n",
    "    region=geometry,\n",
    "    maxPixels=1e9\n",
    ")\n",
    "task.start()\n",
    "print(\"Started export task for similarity image\")\n",
    "\n",
    "# Export high similarity areas as asset (if vectorization succeeded)\n",
    "if 'predicted_matches' in locals():\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        collection=predicted_matches,\n",
    "        description='grain_silo_matches',\n",
    "        assetId='users/your-username/grain_silo_matches'  # Update this path\n",
    "    )\n",
    "    task.start()\n",
    "    print(\"Started export task for predicted matches\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Export code is commented out - uncomment and modify paths as needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0d51d",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated how to use Google's Satellite Embedding dataset for similarity search to identify objects of interest (grain silos) in satellite imagery.\n",
    "\n",
    "### Key Results:\n",
    "- Loaded and processed satellite embedding data for Franklin County, Kansas\n",
    "- Extracted embedding vectors from reference grain silo locations\n",
    "- Computed similarity scores across the entire region using dot product\n",
    "- Applied thresholds to identify potential matches\n",
    "- Visualized results on an interactive map\n",
    "\n",
    "### What we learned:\n",
    "1. **Satellite Embeddings** encode semantic information about land cover and objects\n",
    "2. **Dot Product Similarity** effectively identifies similar features in the embedding space\n",
    "3. **Threshold Selection** is critical - higher thresholds reduce false positives but may miss matches\n",
    "4. **Scale Selection** should match the target object size (10m for small structures)\n",
    "\n",
    "### Potential Improvements:\n",
    "- Use multiple reference examples from different locations/contexts\n",
    "- Experiment with different scales for different object sizes\n",
    "- Apply post-processing filters (e.g., size, shape constraints)\n",
    "- Validate results with ground truth data\n",
    "- Use spatial clustering to reduce duplicate detections\n",
    "\n",
    "### Applications:\n",
    "- Infrastructure mapping (grain silos, solar panels, buildings)\n",
    "- Agricultural asset inventory\n",
    "- Environmental monitoring (identifying similar habitats)\n",
    "- Disaster response (finding similar damage patterns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littoral_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
